---
title: Data Science with NVIDIA Rapids
subtitle: Learning
date: 2016-04-20T00:00:00Z
summary: ''
draft: false
featured: false
authors:
  - admin
lastmod: 2020-12-13T00:00:00Z
tags:
  - Academic
  - Python
  - Data Science
  - NVIDIA
  - Pandas
  - NumPy
  - cuDF
  - cuML

categories:
  - Programming
  - Data Science
projects: []
image:
  caption: ""
  focal_point: ""
  placement: 2
  preview_only: false
---

## Attending NVIDIA's GTC
This past week, I attended [NVIDIA's GTC](https://www.nvidia.com/en-us/gtc/) conference to deepen my understanding of machine learning and artificial intelligence. I heard about GTC and was able to attend through an organization I'm a member of called [Women in Data](https://www.womenindata.org/) where the mission is to "close the gender gap and increase diversity in data careers".




The most rewarding part of the conference for me was being the hands-on training session I attended and




Projects

Fundamentals of Accelerated Data Science (with RAPIDS)
Apr 2021 – Present

Project descriptionProject: Biodefense Simulation
Data: Multiple weeks of data (roads, hospitals, infection rates from population) of virulent epidemic
Scope: Learned core tools to use RAPIDS for everyday data science tasks & scalability methods from workstations and clusters to cloud and HPC

Tasks:
• Calculated measures of geographic spread for each cluster of infected persons
• Compared density of infected vs. uninfected people in each cluster region
• Determined number of individuals closest to each hospital in country
• Prepared road directions for ambulances to hospitals based on coordinates
• Completed logistic regression and decision tree analysis of data to understand magnitude of factors relative impact on risk
• Visualized results with dynamic graphs

Tools Used:
• cuDF, cuGraph, cuXfilter
• cuML (K-means, DBSCAN, logistic regression, k-nearest neighbors, XGBoost)


<!-- # Types of projects needed:

# When In Doubt, Include These Projects:

# The more carefully tailored your portfolio is to the specific jobs you’re applying for, the better the results you’re likely to get. But if you’re applying for entry-level positions, you’re probably casting a wide net, and you’re also likely to be looking at positions that require a lot of the same skills regardless of industry. If you put together a portfolio with at least one project in each of these categories, you’ll be off to an excellent start.

# Data Cleaning Project: Data preparation, data, munging, data cleaning – whatever you want to call it, it accounts for 60-80% of most data science jobs, so you definitely need a project that demonstrates your data scrubbing skills. At a bare minimum, you’ll want to find a messy data set (don’t pick anything that’s already been cleaned), come up with some interesting analytical questions to examine, and then clean the data and perform some basic analysis to answer those questions.

# If you want to step the difficulty up here, collecting your own data (via APIs, web scraping, or some other method) demonstrates some additional skill. Working with unstructured dataof some sort (as opposed to a messy-but-still-structured data set) also looks good.

# Data Storytelling and Visualization Project: Telling stories, offering real insight, and convincing others with data are key parts of any data science job. The best analysis in the world is useless if you can’t get your CEO to understand or take action based on it. This project should take readers on an analytical journey and bring them to a conclusion that’s understandable even to a layperson with little coding or statistical background.

# Data visualization and communication skills will be important here to show and explain what your code is doing. It would be fine to present this in the form of a Jupyter Notebook or in R Markdown, but you could add some extra difficulty with additional polish, like customizing your chart designs or including some interactive elements.

# A Group Project: Working together in a group demonstrates you’ve got communication and collaboration skills, both of which are important for data science jobs. Any type of project could be a group project; what’s important here is to demonstrate that you can function in a team setting both in interpersonal terms (clear communication, fair division of labor, genuine collaboration) and in technical terms (managing projects with Git and GitHub).

# If you want to up the difficulty here, try to get involved with a popular open source project, like contributing to a data-science-related open-source library in a language of your choice. This can be quite difficult, but if you do manage to make a contribution to a popular library or package, this can really make your application stand out to employers.

# For example, Alina Chistyakova, the Lead IT Recruiter at Spice IT Recruitment, says that “successful commits to well-known open-source projects” are one of the things that makes a data science portfolio stand out to her. Kitware HR Director Jeff Hall said that “What really puts a plus in the column of candidates that apply here is having contributed to our specific open-source projects.”

# Other Project Types to Consider

# End-to-End System Building Project: A lot of data science jobs can include building systems that can efficiently analyze regular data sets as they come in, rather than analyzing a single specific data set. For example, you might be tasked with building a dashboard for the sales team that visualizes the company’s sales data and updates regularly as new data comes in.

# This project should show that you’re capable of building a system that can perform the same analysis on new data sets as they’re input, as well as capable of building a system that can be understood and run with relative ease by others. The simplest version of this would be well-commented code that can take data from a public, regularly-updated data set, and perform some analysis. Its README file should explain how it can be used by others, and the project should be relatively easy for other coders to run via the command line.

# If you’d like to step up the difficulty here, the sky’s the limit: you could build full-fledged interactive web dashboards, or build a system that handles real-time/streaming data. The key here is just to show that you can build an analytical system that’s reusable and that other people, or at the very least other programmers, can understand.

# Explanatory Blog Post, Article, or Talk: Being able to explain complex technical concepts in simple, understandable terms is a valuable skill for any data scientist, so explaining some technical concept in a blog post, article, or conference talk can be a great addition to your portfolio if it’s done well. Just be sure to pick a topic that’s suitably complex, and one that you understand and can explain. A blog post explaining what’s happening under the hood in a machine learning algorithm that’s frequently used in your target industry, for example, could be a great inclusion to a portfolio.

# https://www.dataoptimal.com/data-science-projects-2018/

# The ability to communicate
# The ability to collaborate with others
# Technical competence
# The ability to reason about data
# The motivation and ability to take initiative -->
